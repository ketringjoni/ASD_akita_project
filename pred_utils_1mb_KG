#!/usr/bin/env python
# coding: utf-8

# # # # # # # # # # # # # # # # # # 
# Load required packages
import os
import json
import numpy as np
import pandas as pd
from scipy.stats import pearsonr
from scipy.stats import spearmanr
from statsmodels.stats.multitest import fdrcorrection
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
import math

from collections import Counter
from itertools import compress

import io

from Bio.Seq import Seq

import cooler
import astropy
from astropy.convolution import Gaussian2DKernel
from astropy.convolution import convolve
kernel = Gaussian2DKernel(x_stddev=1,x_size=5)

import cooltools
from cooltools.lib.numutils import observed_over_expected
from cooltools.lib.numutils import adaptive_coarsegrain
from cooltools.lib.numutils import interpolate_bad_singletons
from cooltools.lib.numutils import interp_nan, set_diag
from cooltools.lib.plotting import *

from bioframe.io.formats import read_bigwig

import tensorflow as tf
#import tensor2tensor
if tf.__version__[0] == '1':
    tf.compat.v1.enable_eager_execution()

from basenji import dataset
from basenji import seqnn
from basenji import dna_io
from basenji import layers

import pysam
import scipy
from scipy.ndimage import convolve

from itertools import chain
from pybedtools import bedtool

# # # # # # # # # # # # # # # # # # 
# Load the model

base_path = "/pollard/home/ketringjoni/Akita/akita_imaging"
fasta_file = '/pollard/data/vertebrate_genomes/human/hg38/hg38/hg38.fa'
cooler_file = '/pollard/data/chromatin_organization/Krietenstein2019/H1hESC_hg38_4DNFI1O6IL1Q.mapq_30.2048.cool'
genome_hic_cool = cooler.Cooler(cooler_file)

hg38_lengths = pd.read_table("/pollard/home/ketringjoni/genome/hg38/chrom_lengths", header = None, names = ['CHROM', 'chrom_max'])

model_path = '{}/sept14_model'.format(base_path)
half_patch_size = 2**19
MB = 2*half_patch_size
pixel_size = 2048

params_file = model_path+'/params.json'
model_file  = model_path+'/model_best.h5'
with open(params_file) as params_open:
    params = json.load(params_open)
    params_model = params['model']
    params_train = params['train']

params_model['augment_shift']=0

seq_length = params_model['seq_length']
target_length = params_model['target_length']

seqnn_model = seqnn.SeqNN(params_model)

hic_diags = 2
tlen = (target_length-hic_diags) * (target_length-hic_diags+1) // 2

bin_size = seq_length//target_length

seqnn_model.restore(model_file)
print('successfully loaded')

hic_params = params['model']['head_hic']
cropping = hic_params[5]['cropping']
target_length_cropped = target_length - 2 * cropping


# # # # # # # # # # # # # # # # # # 
# Functions to return matrices

def from_upper_triu(vector_repr, matrix_len, num_diags):
    z = np.zeros((matrix_len,matrix_len))
    triu_tup = np.triu_indices(matrix_len,num_diags)
    z[triu_tup] = vector_repr
    for i in range(-num_diags+1,num_diags):
        set_diag(z, np.nan, i)
    return z + z.T

def interp_all_nans(a_init, pad_zeros=True):
    init_shape = np.shape(a_init)
    if len(init_shape) == 2 and init_shape[0] != 1 and init_shape[1] !=1:
        #print('going for 2D')
        if pad_zeros == True:
            a = np.zeros((init_shape[0]+2,init_shape[1]+2))
            a[1:-1,1:-1] = a_init
        else:
            a = a_init
        x, y = np.indices(a.shape)
        interp = np.array(a)
        interp[np.isnan(interp)] = scipy.interpolate.griddata(
                 (x[~np.isnan(a)], y[~np.isnan(a)]), # points we know
                  a[~np.isnan(a)],                    # values we know
                 (x[np.isnan(a)], y[np.isnan(a)]) ,method='linear')
        if pad_zeros == True:
            return interp[1:-1,1:-1]
        else:
            return interp

        
def read_vcf(path):
    
    # Read vcf files and relabel their columns
    
    with open(path, 'r') as f:
        lines = [l for l in f if not l.startswith('##')]
    return pd.read_csv(
        io.StringIO(''.join(lines)),
        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,
               'QUAL': str, 'FILTER': str, 'INFO': str},
        sep='\t'
    ).rename(columns={'#CHROM': 'CHROM'})



# # # # # # # # # # # # # # # # # # 
# Functions to read in sequence and create a variant
fasta_open = pysam.Fastafile(fasta_file)

def makeDel_shiftRight(chrm, seq_start, seq_end, del_start, del_end):
    #print("Window length: ", seq_end-seq_start)
    del_len = del_end-del_start
    seq_start_del, seq_stop_del =  seq_start ,   seq_end+del_len   
    print("The right-padded deletion window starts at {} and ends at {}.".format(seq_start_del, seq_stop_del))
    seq = fasta_open.fetch( chrm, seq_start_del, seq_stop_del ).upper()
    #print("Sequence length: ", len(seq))
    #print("New window length: ", len(seq)-del_len)

    seq_del = dna_io.dna_1hot(seq) # this function has changed, no longer takes n_random=False
    #print("One hot dimensions: ", len(seq_del))
    
    seq_del  = np.vstack((seq_del[ :(del_start-seq_start_del),:],
                          seq_del[(del_end-seq_start_del):, :] ))
    return seq_del

def makeDel_shiftLeft(chrm, seq_start, seq_end, del_start, del_end):
    #print("Window length: ", seq_end-seq_start)
    del_len = del_end-del_start
    seq_start_del, seq_stop_del =  seq_start-del_len ,   seq_end   
    print("The left-padded deletion window starts at {} and ends at {}.".format(seq_start_del, seq_stop_del))
    seq = fasta_open.fetch( chrm, seq_start_del, seq_stop_del ).upper()
    #print("Sequence length: ", len(seq))
    #print("New window length: ", len(seq)-del_len)

    seq_del = dna_io.dna_1hot(seq) # this function has changed, no longer takes n_random=False
    #print("One hot dimensions: ", len(seq_del))
    seq_del  = np.vstack((seq_del[ :(del_start-seq_start_del),:],
                          seq_del[(del_end-seq_start_del):, :] ))  
    return seq_del

def makeDel_symmetric(chrm, seq_start, seq_end, del_start, del_end): # annotated by KatieG
    #print("Window length: ", seq_end-seq_start)
    del_len = del_end-del_start
    seq_start_del, seq_stop_del =  seq_start-del_len//2,   (seq_end+del_len//2)
    
    if (seq_stop_del - seq_start_del - del_len) != (2*half_patch_size): # why would it not equal the length of the ref sequence
        to_add = 2*half_patch_size - (seq_stop_del - seq_start_del - del_len)
        seq_stop_del += to_add # add to_add to seq_stop_del and save as new value
    seq = fasta_open.fetch( chrm, seq_start_del, seq_stop_del ).upper()
    print("The sym-padded deletion window starts at {} and ends at {}.".format(seq_start_del, seq_stop_del))
    #print("Sequence length: ", len(seq))
    #print("New window length: ", len(seq)-del_len)

    # one hot encode DNA sequence: 
    seq_del = dna_io.dna_1hot(seq)  # this function has changed, n_random no longer 
    #print("One hot dimensions: ", len(seq_del))
    
    # create sequence with the deletion
    seq_del  = np.vstack((seq_del[ :(del_start-seq_start_del),:], # get sequence from beginning to start of deletion
                          seq_del[(del_end-seq_start_del):, :] )) # get sequence from end of deletion to end of sequence
    return seq_del



# # # # # # # # # # # # # # # # # # 
# Highest-level prediction/scoring functions

# function to return prediction given chr/start/stop
def predict_wt(region_chr, region_start, region_stop):
    
    # if there are less than 1048576bp in region, adjust
    if region_stop-region_start != (2*half_patch_size):
        to_add = 2*half_patch_size - (region_stop - region_start)
        print("Adding an additional {} basepairs due to SV being odd".format(to_add))
        region_stop += to_add
    
    seq = fasta_open.fetch( region_chr, region_start, region_stop ).upper() 
    seq_1hot = dna_io.dna_1hot(seq) # this function has changes, no longer uses n_random = False
    
    
    ensemble_shifts=[0,-5,5]
    sequence = tf.keras.Input(shape=(seqnn_model.seq_length, 4), name='sequence')
    sequences = [sequence]
    
    if len(ensemble_shifts) > 1:
        # generate shifted sequences
        sequences = layers.EnsembleShift(ensemble_shifts)(sequences)
    sequences
    
    #sequences_rev = [(seq,tf.constant(False)) for seq in sequences]
    #preds = [layers.SwitchReverse()([seqnn_model.model(seq), rp]) for (seq,rp) in sequences_rev]
    
    pred_targets = seqnn_model.predict(np.expand_dims(seq_1hot,0) )    
    mat = from_upper_triu(pred_targets[0,:,0],target_length_cropped,2)
    mat_denan = interp_all_nans(mat) # I think this makes NAs a number between the one before and after
    return(mat_denan)

def predict_wt_targets(region_chr, region_start, region_stop):
    
    # if there are less than 1048576bp in region, adjust
    if region_stop-region_start != (2*half_patch_size):
        to_add = 2*half_patch_size - (region_stop - region_start)
        print("Adding an additional {} basepairs due to SV being odd".format(to_add))
        region_stop += to_add
    
    seq = fasta_open.fetch( region_chr, region_start, region_stop ).upper() 
    seq_1hot = dna_io.dna_1hot(seq) # this function has changes, no longer uses n_random = False
    
    
    ensemble_shifts=[0,-5,5]
    sequence = tf.keras.Input(shape=(seqnn_model.seq_length, 4), name='sequence')
    sequences = [sequence]
    
    if len(ensemble_shifts) > 1:
        # generate shifted sequences
        sequences = layers.EnsembleShift(ensemble_shifts)(sequences)
    sequences
    
    #sequences_rev = [(seq,tf.constant(False)) for seq in sequences]
    #preds = [layers.SwitchReverse()([seqnn_model.model(seq), rp]) for (seq,rp) in sequences_rev]
    
    pred_targets = seqnn_model.predict(np.expand_dims(seq_1hot,0) ) 
    pred_targets_vector = pred_targets[0,:,0]
    
    return(pred_targets_vector)

def get_mat_from_vector(pred_targets):
    mat = from_upper_triu(pred_targets,target_length_cropped,2)
    mat_denan = interp_all_nans(mat)
    return(mat_denan)



# function to return prediction given window and deletion coordinates
def predict_del(region_chr, region_start, region_stop, del_start, del_stop):

    seq_1hot = makeDel_symmetric(region_chr, region_start, region_stop, del_start, del_stop)
    pred_targets = seqnn_model.predict(   np.expand_dims(seq_1hot,0) )    
    mat = from_upper_triu(pred_targets[0,:,0],target_length_cropped,2)
    mat_denan = interp_all_nans(mat)
    return(mat_denan)

def predict_del_targets(region_chr, region_start, region_stop, del_start, del_stop):

    seq_1hot = makeDel_symmetric(region_chr, region_start, region_stop, del_start, del_stop)
    pred_targets = seqnn_model.predict(   np.expand_dims(seq_1hot,0) )  
    pred_targets_vector = pred_targets[0,:,0]
    return(pred_targets_vector)

####################################
# Function to mask matrices

def mask_mat_del(mat_del, del_start, del_stop, shift):
    
    # Adapted from Maureen's mask_mat
    
    del_half = round( (del_stop - del_start) /2 )
    start_wt = int(del_start + del_half - half_patch_size) + 32*2048
    stop_wt = int(del_stop - del_half + half_patch_size) - 32*2048
    
    nrow = mat_del.shape[0]
    
    # number of bp per bin
    bp_per_pix = (stop_wt - start_wt) / nrow 
    
    pix_coords = []
    rows_to_mask = []
    
    # iterate over each bin in the sequence
    for j in range(0,nrow):
        
        # get coordinates for each bin in the sequence
        pix_start = bp_per_pix*j + start_wt 
        pix_stop = bp_per_pix*(j+1) + start_wt
        pix_coords.append(tuple([pix_start, pix_stop])) 

        # get bins that overlap the deletion
        if pix_stop > del_start and pix_start < del_stop: 
            rows_to_mask.append(j)
            
    #del mask
    del_masked = mat_del.copy()    
    
    if shift == "right":
        for j in rows_to_mask:
            del_masked = np.insert(del_masked, j, np.nan, axis=0)
            del_masked = np.insert(del_masked, j, np.nan, axis=1)
        del_masked = del_masked[0:target_length_cropped, 0:target_length_cropped]
            
    elif shift == "left":
        # Remove padded columns
        
        del_masked = del_masked[int(len(rows_to_mask)):, int(len(rows_to_mask)):]
        for j in rows_to_mask:
            del_masked = np.insert(del_masked, j, np.nan, axis=0)
            del_masked = np.insert(del_masked, j, np.nan, axis=1)
            
    elif shift == "sym":
        
        # Chop off the outside of the matrix that is out of the frame of the wt sequence
        del_masked = del_masked[int(len(rows_to_mask)/2):, int(len(rows_to_mask)/2):] # remove columns and rows half the size of the deletion
        
        for j in rows_to_mask:
            
            # insert nans (don't remove anything)
            del_masked = np.insert(del_masked, j, np.nan, axis=0) 
            del_masked = np.insert(del_masked, j, np.nan, axis=1)
            
        # remove bottom right of matrix
        del_masked = del_masked[0:target_length_cropped, 0:target_length_cropped]
            
    return del_masked


####################################
# copy the following over from run_var_chrom1.py 

def run_sequence(seq):
    seq_1hot = dna_io.dna_1hot(seq)
    ensemble_shifts=[0,-5,5]
    sequence = tf.keras.Input(shape=(seqnn_model.seq_length, 4), name='sequence')
    sequences = [sequence]
    
    if len(ensemble_shifts) > 1:
        # generate shifted sequences
        sequences = layers.EnsembleShift(ensemble_shifts)(sequences)
    
    #sequences_rev = [(seq,tf.constant(False)) for seq in sequences]
    #preds = [layers.SwitchReverse()([seqnn_model.model(seq), rp]) for (seq,rp) in sequences_rev]
    
    pred_targets = seqnn_model.model(np.expand_dims(seq_1hot,0) )    
    mat = pred.from_upper_triu(pred_targets[0,:,0],target_length_cropped,2)
    return(mat)


def plot_two_mats(wt_mat, alt_mat):
    
        # EXAMPLE: Pulling from the test set. 

    # pull known test example
    #seq = 'chr15:89737238-89737248'

    # split location
    #chrm,start,stop = seq.split(':')[0], seq.split(':')[1].split('-')[0], seq.split(':')[1].split('-')[1]

    # pull index
    target_index = 0 # HFF 

    # regather string
    #chrm, seq_start, seq_end = sequences_test.iloc[test_index][0:3]
    #myseq_str = chrm+':'+str(seq_start)+'-'+str(seq_end)
    #print(myseq_str)

    #test_target = test_targets[test_index:test_index+1,:,:] # grab target on test inputs
    #test_pred = seqnn_model.model.predict(test_inputs[test_index:test_index+1,:,:]) # make prediction on test inputs

    plt.figure(figsize=(12,10))
    target_index = 0
    vmin=-2; vmax=2

    # plot pred
    plt.subplot(121) 
    #mat = from_upper_triu(test_pred[:,:,target_index], target_length1_cropped, hic_diags)
    im = plt.matshow(wt_mat, fignum=False, cmap= 'RdBu_r', vmax=vmax, vmin=vmin)
    plt.colorbar(im, fraction=.04, pad = 0.05, ticks=[-2,-1, 0, 1,2]);
    plt.title('Wildtype Prediction',y=1.15 )
    #plt.ylabel(myseq_str)

    # plot target 
    plt.subplot(122) 
    #mat = from_upper_triu(test_target[:,:,target_index], target_length1_cropped, hic_diags)
    im = plt.matshow(alt_mat, fignum=False, cmap= 'RdBu_r', vmax=vmax, vmin=vmin)
    plt.colorbar(im, fraction=.04, pad = 0.05, ticks=[-2,-1, 0, 1,2]);
    plt.title( 'Alternate Prediction',y=1.15)

    plt.tight_layout()
    plt.show()



####################################
# Functions I wrote


def get_correlation_track(wt_pred, del_pred_masked):

    # Get vector with correlation score between wt and masked deletion matrix at each bin
    
    spearman_list = []
    for i in range(0,len(wt_pred)):
        # If the whole row is nans, append nan, if not
        if np.count_nonzero(np.isnan(del_pred_masked[i])) == len(del_pred_masked[i]):
            spearman_list.append([np.nan, np.nan])
        else:
            spearman_results = spearmanr(wt_pred[i], del_pred_masked[i], axis=0, nan_policy='omit') # ignores nans
            spearman_list.append(spearman_results)


    # Get nan indexes
    nan_indexes = np.unique(np.argwhere(np.isnan(spearman_list))[:,0])


    # Remove nans and correct for multiple testing with FDR

    # Remove nans
    spearman_array = np.array(spearman_list) 
    spearman_array_nonan = np.delete(spearman_array, nan_indexes, axis = 0)

    # FDR correct pvalues
    pvals = spearman_array_nonan[:,1]
    spearman_array_nonan[:,1] = fdrcorrection(pvals, alpha=0.05, method='indep', is_sorted=False)[1]

    # Make non-significant correlations 0
    for i in range(0,len(spearman_array_nonan)):
        if spearman_array_nonan[i,1] >= 0.05:
            spearman_array_nonan[i,0] = 0

    corr = spearman_array_nonan[:,0]

    # Re-insert nans
    for i in nan_indexes:
        corr = np.insert(corr, i, np.nan, axis=0)

    return corr


def get_disruption_track(mat1, mat2):

    # Get vector with disruption score between wt and masked deletion matrix at each bin
    
    # A vecotr of sum of squared differences for each row of matrix 
    sub_mat = mat1 - mat2
    
    # Get number of bins that are not nan (not including ones that overlap deletion)
    non_nan_values = np.count_nonzero(np.invert(np.isnan(sub_mat[0])))
    
    disruption_list = []
    for i in range(0,len(sub_mat)):
        row_sum = np.nansum([x**2 for x in sub_mat[i]])
        if row_sum == 0:
            row_sum = np.nan
        row_avg = row_sum/non_nan_values
        disruption_list.append(row_avg)

    return disruption_list


def get_disruption_score(mat1, mat2):

    # Get MSE disruption score between (masked) matrices
    
    # MSD = sum of all (sum of squared differences for each row of matrix)
    sub_mat = mat1 - mat2
    
    # Get number of bins that are not nan (not including ones that overlap deletion)
    non_nan_values = np.count_nonzero(np.invert(np.isnan(sub_mat[0])))
    
    disruption_list = []
    for i in range(0,len(sub_mat)):
        row_sum = np.nansum([x**2 for x in sub_mat[i]])
        if row_sum == 0:
            row_sum = np.nan
        row_avg = row_sum/non_nan_values
        disruption_list.append(row_sum)
        
    disruption_score = np.nansum(disruption_list)/non_nan_values # treat NAs as 0s

    return disruption_score



def get_DS_from_vector(vector1, vector2):

    # Get disruption score between wt and variant vectors
    
    # A vecotr of sum of squared differences for each row of matrix 
    sub_vec = [x - y for x,y in zip(vector1, vector2)]
    
    # Get number of bins that are not nan (not including ones that overlap deletion)
    non_nan_values = np.count_nonzero(np.invert(np.isnan(sub_vec)))
    
    MSE = np.nansum([x**2 for x in sub_vec])/non_nan_values

    return MSE




def get_variant_position(CHR, POS, var_len, half_left, half_right):

    # Define variant position with respect to chromosome start and end

    # Get last coordinate of chromosome
    chrom_max = int(hg38_lengths[hg38_lengths.CHROM == CHR[3:]]['chrom_max']) 
    
    if (POS - half_left > 0) and (POS + var_len - 1 + half_right <= chrom_max):
        var_position = "chrom_mid"

    # If variant too close to the beginning of chromosome
    elif POS - half_left <= 0: 
        var_position = "chrom_start"
        #print("Warning: Variant not centered; too close to start of chromosome")

    # If variant too close to the end of chromosome
    elif POS + var_len - 1 + half_right > chrom_max: 
        var_position = "chrom_end"
        #print("Warning: Variant not centered; too close to end of chromosome")
        
    return var_position



def mat_from_seq(seq):
    
    # Get predicted matrix from ~1MB sequence
    
    seq_1hot = dna_io.dna_1hot(seq) 

    ensemble_shifts=[0,-5,5]
    sequence = tf.keras.Input(shape=(seqnn_model.seq_length, 4), name='sequence')
    sequences = [sequence]

    if len(ensemble_shifts) > 1:
        sequences = layers.EnsembleShift(ensemble_shifts)(sequences)
    sequences

    pred_targets = seqnn_model.predict(np.expand_dims(seq_1hot,0) )    
    mat = from_upper_triu(pred_targets[0,:,0],target_length_cropped,2)
    #mat_denan = interp_all_nans(mat) 

    return mat


def vector_from_seq(seq):
    
    # Get predicted matrix from ~1MB sequence
    
    seq_1hot = dna_io.dna_1hot(seq) 

    ensemble_shifts=[0,-5,5]
    sequence = tf.keras.Input(shape=(seqnn_model.seq_length, 4), name='sequence')
    sequences = [sequence]

    if len(ensemble_shifts) > 1:
        sequences = layers.EnsembleShift(ensemble_shifts)(sequences)
    sequences

    pred_targets = seqnn_model.predict(np.expand_dims(seq_1hot,0))[0,:,0]    

    return pred_targets



def mat_from_vector(pred_targets):
    
    mat = from_upper_triu(pred_targets,target_length_cropped,2)
    mat_denan = interp_all_nans(mat) 

    return mat_denan
    

def get_variant_type(REF, ALT):

    # Annotate variant as one of the 6 categories below based on REF and ALT allele
    
    if len(REF) > len(ALT) and ALT in REF:
        variant_type = "Deletion"
    elif len(REF) < len(ALT) and REF in ALT:
        variant_type = "Insertion"
        
    elif len(REF) > len(ALT) and ~(ALT in REF):
        variant_type = "Del_sub"
    elif len(REF) < len(ALT) and ~(REF in ALT):
        variant_type = "Ins_sub"
        
    elif len(REF) == 1 and len(ALT) ==1:
        variant_type = "SNP"
    elif len(REF) == len(ALT) and len(REF) != 1:
        variant_type = "MNP"
    
    return variant_type


def get_bin(x):
    
    # Get the bin number based on bp number in a sequence (ex: 2500th bp is in the 2nd bin)
    
    x_bin = math.ceil(x/pixel_size)
    return x_bin




def get_sequence(CHR, POS, REF, ALT):
  
    # Get reference and alternate sequence from REF and ALT allele using reference genome 
    
    
    # Get reference sequence
    
    REF_len = len(REF)

    REF_half_left = math.ceil((MB - REF_len)/2) # if the REF allele is odd, shift right
    REF_half_right = math.floor((MB - REF_len)/2)

    # Annotate wether variant is close to beginning or end of chromosome
    var_position = get_variant_position(CHR, POS, REF_len, REF_half_left, REF_half_right)



    # Get start and end of reference sequence

    if var_position == "chrom_mid":
        REF_start = POS - REF_half_left
        REF_stop = REF_start + MB 

    elif var_position == "chrom_start": 
        REF_start = 0
        REF_stop = MB

    elif var_position == "chrom_end": 
        REF_stop = chrom_max
        REF_start = chrom_max - MB



    # Get reference sequence
    REF_seq = fasta_open.fetch(CHR, REF_start, REF_stop).upper()


    # Warn if Ns are more than 5% of sequence
    if Counter(REF_seq)['N']/MB*100 > 5:
        #print("Warning: N composition greater than 5%")
        raise ValueError('N composition greater than 5%')



    # Make sure that reference sequence matches given REF

    if var_position == "chrom_mid":
        assert(REF_seq[(REF_half_left - 1) : (REF_half_left - 1 + REF_len)] == REF)

    elif var_position == "chrom_start": 
        assert(REF_seq[(POS - 1) : (POS - 1 + REF_len)] == REF) 

    elif var_position == "chrom_end": 
        assert(REF_seq[-(REF_stop - POS + 1) : -(REF_stop - POS + 1 - REF_len)] == REF)


    assert(len(REF_seq) == MB)





    # For SNPs, MNPs, Insertions, or Ins_subs: 
    if len(REF) <= len(ALT):

        # Create alternate sequence: change REF sequence at position from REF to ALT

        ALT_seq = REF_seq

        if var_position == "chrom_mid":
            ALT_seq = ALT_seq[:(REF_half_left - 1)] + ALT + ALT_seq[(REF_half_left - 1 + REF_len):]

        elif var_position == "chrom_start": 
            ALT_seq = ALT_seq[:(POS - 1)] + ALT + ALT_seq[(POS - 1 + REF_len):]

        elif var_position == "chrom_end": 
            ALT_seq = ALT_seq[:-(REF_stop - POS + 1)] + ALT + ALT_seq[-(REF_stop - POS + 1 - REF_len):]
            
            


        # Chop off ends of alternate sequence if it's longer 
        if len(ALT_seq) > len(REF_seq):
            to_remove = (len(ALT_seq) - len(REF_seq))/2

            if to_remove == 0.5:
                ALT_seq = ALT_seq[1:]
            else:
                ALT_seq = ALT_seq[math.ceil(to_remove) : -math.floor(to_remove)]


    # For Deletions of Del_subs
    elif len(REF) > len(ALT):


        del_len = len(REF) - len(ALT)
        
        to_add_left = math.ceil(del_len/2)
        to_add_right = math.floor(del_len/2)
        

        # Get start and end of reference sequence

        if var_position == "chrom_mid":
            ALT_start = REF_start - to_add_left
            ALT_stop = REF_stop + to_add_right

        elif var_position == "chrom_start": 
            ALT_start = 0
            ALT_stop = MB + del_len

        elif var_position == "chrom_end": 
            ALT_stop = chrom_max
            ALT_start = chrom_max - MB - del_len


        # Get alternate sequence
        ALT_seq = fasta_open.fetch(CHR, ALT_start, ALT_stop).upper()
        
        
        
        # Make sure that alternate sequence matches REF at POS

        if var_position == "chrom_mid":
            assert(ALT_seq[(REF_half_left - 1 + to_add_left) : (REF_half_left - 1 + to_add_left + REF_len)] == REF)

        elif var_position == "chrom_start": 
            assert(ALT_seq[(POS - 1) : (POS - 1 + REF_len)] == REF)

        elif var_position == "chrom_end": 
            assert(ALT_seq[(end - POS) : (end - POS + REF_len)] == REF)


    
        # Change alternate sequence to match ALT at POS

        if var_position == "chrom_mid":
            # [:N] does not include N but [N:] includes N
            ALT_seq = ALT_seq[:(REF_half_left - 1 + to_add_left)] + ALT + ALT_seq[(REF_half_left - 1 + to_add_left + REF_len):] 

        elif var_position == "chrom_start": 
            ALT_seq = ALT_seq[:(POS - 1)] + ALT + ALT_seq[(POS - 1 + REF_len):]

        elif var_position == "chrom_end": 
            ALT_seq = ALT_seq[:- POS] + ALT + ALT_seq[(- POS + REF_len):]

            
    assert(len(ALT_seq) == MB)
        
        
    return REF_seq, ALT_seq



# Mask matrices

def mask_matrices(REF, ALT, REF_pred, ALT_pred):

    # Mask reference and alternate predicted matrices, based on the type of variant, when they are centered in the sequence
    
    
    variant_type = get_variant_type(REF, ALT)
    
    # Insertions: Mask REF, add nans if necessary, and mirror nans to ALT
    if variant_type in ["Insertion", "Ins_sub"]:

    # start with just the middle of the chromosome

        # Adjust reference sequence

        REF_len = len(REF)

        REF_half_left = math.ceil((MB - REF_len)/2) # if the REF allele is odd, shift right
        REF_half_right = math.floor((MB - REF_len)/2)

        # change REF allele to nans
        var_start = get_bin(REF_half_left - 1) - 32
        var_end = get_bin(REF_half_left - 1 + REF_len) - 32

        REF_pred_masked = REF_pred

        REF_pred_masked[var_start:var_end + 1, :] = np.nan
        REF_pred_masked[:, var_start:var_end + 1] = np.nan


        # Get start and end of ALT allele
        ALT_len = len(ALT)
        
        ALT_half_left = math.ceil((MB - ALT_len)/2) 
        ALT_half_right = math.floor((MB - ALT_len)/2)

        var_start_ALT = get_bin(ALT_half_left - 1) - 32
        var_end_ALT = get_bin(ALT_half_right - 1 + ALT_len) - 32
        
        
        
        # If the ALT allele falls on more bins than the REF allele, adjust ALT allele 
            # (add nan(s) to var and remove outside bin(s))
            # Otherwise don't mask
        
        if var_end_ALT - var_start_ALT > var_end - var_start:
            
        
            # Insert the rest of the nans corresponding to the ALT allele
            to_add = (var_end_ALT - var_start_ALT) - (var_end - var_start)

            for j in range(var_start, var_start + to_add): # range only includes the first variable 
                REF_pred_masked = np.insert(REF_pred_masked, j, np.nan, axis = 0)
                REF_pred_masked = np.insert(REF_pred_masked, j, np.nan, axis = 1)

            # Chop off the outside of the REF matrix 
            to_remove = (len(REF_pred_masked) - 448)/2

            REF_pred_masked = REF_pred_masked[math.floor(to_remove) : -math.ceil(to_remove), math.floor(to_remove) : -math.ceil(to_remove)]
            # remove less on the left bc that's where you put one less part of the variant with odd number of bp

            assert(len(REF_pred_masked) == 448)
            
            
        

        # Adjust alternate sequence

        # make all nans in REF_pred also nan in ALT_pred

        # change all nan
        REF_pred_novalues = REF_pred_masked.copy()

        REF_pred_novalues[np.invert(np.isnan(REF_pred_novalues))] = 0

        ALT_pred_masked = ALT_pred + REF_pred_novalues

        assert(len(ALT_pred_masked) == 448)
        
    
    
    # Deletions: Mask ALT, add nans if necessary, and mirror nans to REF
    elif variant_type in ["Deletion", "Del_sub"]:
        
        ALT_len = len(ALT)

        ALT_half_left = math.ceil((MB - ALT_len)/2) # if the ALT allele is odd, shift right
        ALT_half_right = math.floor((MB - ALT_len)/2)

        # change ALT allele to nans
        var_start = get_bin(ALT_half_left - 1) - 32
        var_end = get_bin(ALT_half_left - 1 + ALT_len) - 32

        ALT_pred_masked = ALT_pred

        ALT_pred_masked[var_start:var_end + 1, :] = np.nan
        ALT_pred_masked[:, var_start:var_end + 1] = np.nan


        
        # Get start and end of ALT allele
        REF_len = len(REF)
        
        REF_half_left = math.ceil((MB - REF_len)/2) 
        REF_half_right = math.floor((MB - REF_len)/2)

        var_start_REF = get_bin(REF_half_left - 1) - 32
        var_end_REF = get_bin(REF_half_right - 1 + REF_len) - 32
        
        
        
        # If the REF allele falls on more bins than the ALT allele, adjust REF allele 
            # (add nan(s) to var and remove outside bin(s))
            # Otherwise don't mask
        
        if var_end_REF - var_start_REF > var_end - var_start:
            
        
        
            # Insert the rest of the nans corresponding to the REF allele
            to_add = (var_end_REF - var_start_REF) - (var_end - var_start)

            for j in range(var_start, var_start + to_add): # range only includes the first variable 
                ALT_pred_masked = np.insert(ALT_pred_masked, j, np.nan, axis = 0)
                ALT_pred_masked = np.insert(ALT_pred_masked, j, np.nan, axis = 1)


            # Chop off the outside of the ALT matrix 
            to_remove = (len(ALT_pred_masked) - 448)/2

            ALT_pred_masked = ALT_pred_masked[math.floor(to_remove) : -math.ceil(to_remove), math.floor(to_remove) : -math.ceil(to_remove)]
            # remove less on the left bc that's where you put one less part of the variant with odd number of bp


            assert(len(ALT_pred_masked) == 448)


        # Adjust Reference sequence

        # make all nans in ALT_pred also nan in REF_pred

        # change all nan
        ALT_pred_novalues = ALT_pred_masked.copy()

        ALT_pred_novalues[np.invert(np.isnan(ALT_pred_novalues))] = 0

        REF_pred_masked = REF_pred + ALT_pred_novalues

        assert(len(REF_pred_masked) == 448)

    
    # SNPs or MNPs: Mask REF and mirror nans to ALT
    elif variant_type in ['SNP', 'MNP']:
        
        # start with just the middle of the chromosome

        # Adjust reference sequence

        REF_len = len(REF)

        REF_half_left = math.ceil((MB - REF_len)/2) # if the REF allele is odd, shift right
        REF_half_right = math.floor((MB - REF_len)/2)

        # change REF allele to nans
        var_start = get_bin(REF_half_left - 1) - 32
        var_end = get_bin(REF_half_left - 1 + REF_len) - 32

        REF_pred_masked = REF_pred

        REF_pred_masked[var_start:var_end + 1, :] = np.nan
        REF_pred_masked[:, var_start:var_end + 1] = np.nan

        
        # Adjust alternate sequence

        # make all nans in REF_pred also nan in ALT_pred

        # change all nan
        REF_pred_novalues = REF_pred_masked.copy()

        REF_pred_novalues[np.invert(np.isnan(REF_pred_novalues))] = 0

        ALT_pred_masked = ALT_pred + REF_pred_novalues

        assert(len(ALT_pred_masked) == 448)
        
    
    
    return REF_pred_masked, ALT_pred_masked









