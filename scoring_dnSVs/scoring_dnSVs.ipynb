{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef4c9ee-1244-4c89-9805-987bffd3bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "repo_dir = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9be67-b819-497a-8b28-0c6fd7e7a519",
   "metadata": {},
   "source": [
    "# Scoring dnSVs using SuPreMo-Akita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5bf30ec-a6c5-467f-b34b-283c484c1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input for SuPreMo\n",
    "dnSVs = pd.read_csv(f'{repo_dir}data/SFARI_SSC_dnSVs.csv').rename(columns = {'#chrom':'chrom'})\n",
    "dnSVs_for_supremo = dnSVs[[x in ['DEL', 'DUP', 'INV'] for x in dnSVs.svtype]][['chrom', 'pos', 'end', 'svtype', 'svlen']].drop_duplicates()\n",
    "dnSVs_for_supremo.insert(2, 'REF', '-')\n",
    "dnSVs_for_supremo.insert(3, 'ALT', '-')\n",
    "dnSVs_for_supremo.columns = ['CHROM', 'POS', 'REF', 'ALT', 'END', 'SVTYPE', 'SVLEN']\n",
    "dnSVs_for_supremo.to_csv(f'{repo_dir}data/dnSVs_for_SuPreMo.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a09e05ce-0bf2-4a3c-b585-669c32ce34a0",
   "metadata": {},
   "source": [
    "Run SuPreMo:\n",
    "\n",
    "SuPreMo/scripts/SuPreMo.py data/SSC_dnSV_for_SuPreMo.txt \\\n",
    "--get_Akita_scores \\\n",
    "--shift_by -1 0 1 \\\n",
    "--revcomp add_revcomp \\\n",
    "--dir scoring_dnSVs/supremo-akita_output \\\n",
    "--file SSC_dnSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa3e1b6c-4109-4290-a77b-8984f1ed97e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pollard/home/ketringjoni/miniconda3/envs/get_Akita_scores_env/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/pollard/home/ketringjoni/miniconda3/envs/get_Akita_scores_env/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    }
   ],
   "source": [
    "# Read SuPreMo output and save to file\n",
    "\n",
    "supremo_scores = pd.concat([pd.read_csv(f'{repo_dir}data/dnSVs_for_SuPreMo.txt', \n",
    "                                        sep = '\\t'),\n",
    "                            pd.read_csv(f'{repo_dir}scoring_dnSVs/supremo-akita_output/SSC_dnSV_scores', \n",
    "                                        sep = '\\t')],\n",
    "                           axis = 1)\n",
    "\n",
    "supremo_scores['corr_median'] = [np.nanmedian([x,y,z]) for x,y,z in zip(supremo_scores['corr_-1'], \n",
    "                                                                         supremo_scores['corr_0'], \n",
    "                                                                         supremo_scores['corr_0_revcomp'])]\n",
    "supremo_scores['mse_median'] = [np.nanmedian([x,y,z]) for x,y,z in zip(supremo_scores['mse_-1'], \n",
    "                                                                         supremo_scores['mse_0'], \n",
    "                                                                         supremo_scores['mse_0_revcomp'])]\n",
    "\n",
    "supremo_scores.columns = ['chrom', 'pos', 'REF', 'ALT', 'end', 'svtype', 'svlen', 'var_index',\n",
    "       'mse_-1', 'corr_-1', 'mse_0', 'corr_0', 'mse_0_revcomp',\n",
    "       'corr_0_revcomp', 'mse_1', 'corr_1', 'corr_median', 'mse_median']\n",
    "\n",
    "SSC_results_supremo = (dnSVs\n",
    "                       .rename(columns = {'#chrom':'chrom'})\n",
    "                       .merge(supremo_scores.drop(['REF', 'ALT'], axis = 1),\n",
    "                              on = ['chrom', 'pos', 'end', 'svtype', 'svlen'], how = 'left'))\n",
    "\n",
    "SSC_results_supremo.to_csv(f'{repo_dir}data/SFARI_SSC_dnSVs', sep = '\\t', index = False)                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b02d-b525-40d6-9014-60decb446b06",
   "metadata": {},
   "source": [
    "# Scoring dnSVs near CREints using SuPreMo-Akita with weighted scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f94a1-8cce-4e10-81fa-ef40cd58f6a0",
   "metadata": {},
   "source": [
    "## Process PLACseq data into CREints for weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc352cc6-b121-40b5-95c0-dc3977b240be",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0db284f-0aa5-4c59-a809-8153e80b7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d47330b-c11b-41dd-b24f-bdc7ab127c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hg38 promoters of protein-coding genes (Kallisto https://pachterlab.github.io/kallisto/)\n",
    "\n",
    "ensembl = pd.read_csv(f'{repo_dir}data/Homo_sapiens.GRCh38.96.gtf',\n",
    "                     sep='\\t', skiprows=5, header=None, \n",
    "                      names=['chrom','source','desc','start','end','score','strand','score2','desc_further'],\n",
    "                     low_memory=False)\n",
    "ensembl['chr'] = 'chr' + ensembl['chrom'].astype(str)\n",
    "ensembl['name'] = ensembl['desc_further'].str.split('gene_name ').str[1].str.split(';').str[0].str.strip('\"\"')\n",
    "ensembl['biotype'] = ensembl['desc_further'].str.split('biotype ').str[1].str.split(';').str[0].str.strip('\"\"')\n",
    "\n",
    "# Remove nonsense chromosomes\n",
    "chromosomes = []\n",
    "for i in list(range(23))[1:]:\n",
    "    chrom = 'chr' + str(i)\n",
    "    chromosomes.append(chrom)\n",
    "chromosomes.append('chrX')\n",
    "chromosomes.append('chrY')\n",
    "ensembl = ensembl[[x in chromosomes for x in ensembl.chr]]\n",
    "\n",
    "ensembl = ensembl[ensembl.biotype == \"protein_coding\"]\n",
    "ensembl_genes = ensembl.query('desc == \"gene\"').copy()\n",
    "n_ens_genes = pd.DataFrame(ensembl_genes['name'].value_counts())\n",
    "n_ens_genes['gene'] = n_ens_genes.index\n",
    "ensembl_genes_single = n_ens_genes.query('name == 1')['gene'].tolist()\n",
    "ensembl_genes_single_df = ensembl_genes.query('(name in @ensembl_genes_single)').copy()\n",
    "\n",
    "# Get ensemble gene ids\n",
    "ensembl_genes_single_df['gene_id'] = ensembl_genes_single_df['desc_further'].str.split('\"').str[1]\n",
    "ensembl_genes_single_df = ensembl_genes_single_df.rename(columns = {\"name\":\"gene\"})\n",
    "gene_annot = ensembl_genes_single_df[['gene', 'gene_id', 'chr', 'start', 'end', 'strand']]\n",
    "\n",
    "promoter_annot = gene_annot.copy()\n",
    "\n",
    "def label_promoter_start(row):\n",
    "    if row['strand'] == '+' :\n",
    "        return row['start'] - 1000\n",
    "    if row['strand'] == '-' :\n",
    "        return row['end']\n",
    "\n",
    "promoter_annot['Start'] = promoter_annot.apply(lambda row: label_promoter_start(row), axis=1)\n",
    "promoter_annot['Start'][promoter_annot['Start'] < 1] = 1\n",
    "promoter_annot['End'] = promoter_annot['Start'] + 1000\n",
    "\n",
    "promoter_annot_PC_BED = BedTool.from_dataframe(promoter_annot[['chr', 'Start', 'End', 'gene']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e1cc02-ad6f-467c-bfbd-b4e0c11dcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.77350192413414 % of loops are within predictive window\n"
     ]
    }
   ],
   "source": [
    "# Get excitatory neuron H3K4me3 PLACseq loops (Song et al 2021)\n",
    "\n",
    "loops = pd.read_csv(f'{repo_dir}data/eN.MAPS.peaks.txt', sep = '\\t').rename(columns = {'chr1':'chrom'})[['chrom', 'start1', 'end1', 'start2', 'end2']]\n",
    "\n",
    "# Get loops within predictive window \n",
    "\n",
    "dist_cutoff = 900000 #pixel_size*448\n",
    "\n",
    "center_coord1 = [(x+y)/2 for x,y in zip(loops.start1, loops.end1)]\n",
    "center_coord2 = [(x+y)/2 for x,y in zip(loops.start2, loops.end2)]\n",
    "\n",
    "before = len(loops)\n",
    "\n",
    "distance = [abs(x-y) for x,y in zip(center_coord1, center_coord2)]\n",
    "loops = loops[[x < dist_cutoff for x in distance]]\n",
    "\n",
    "print(len(loops)/before*100, '% of loops are within predictive window')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0046878-e2f7-4735-a946-811e0f233c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get excitatory neuron RNAseq data (Song et al 2021)\n",
    "\n",
    "eN_exp = pd.read_csv(f'{repo_dir}data/eN_avg', sep = '\\t').dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "274a1bb6-f990-44a5-a441-61be7f05f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get excitatory neuron ATACseq data (Song et al 2021)\n",
    "\n",
    "ATAC = pd.read_csv(f'{repo_dir}data/eN.ATAC-seq.narrowPeak', sep = '\\t', \n",
    "                   names = ['chrom', 'start', 'end', 'peak_id', 'score', 'strand', 'signalValue', 'pvalue', 'qvalue', 'peak'])\n",
    "ATAC_BED = BedTool.from_dataframe(ATAC[['chrom', 'start', 'end']]).sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b5430-0b29-4e38-a550-c12fc4115091",
   "metadata": {},
   "source": [
    "### Grop nearby loop anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965cf588-5490-4370-9e2d-36f67005a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get left and right loops\n",
    "\n",
    "left_loops = loops[['chrom', 'start1', 'end1']].drop_duplicates().reset_index(drop = True)\n",
    "left_loops['left_index'] = left_loops.index\n",
    "loops = loops.merge(left_loops, on = ['chrom', 'start1', 'end1'])\n",
    "\n",
    "right_loops = loops[['chrom', 'start2', 'end2']].drop_duplicates().reset_index(drop = True)\n",
    "right_loops['right_index'] = right_loops.index\n",
    "loops = loops.merge(right_loops, on = ['chrom', 'start2', 'end2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a935b4-9fec-43d7-94bf-30db8a859a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all loops with the same left anchor, combine right anchors that are within d\n",
    "\n",
    "d = 10000\n",
    "\n",
    "for i in left_loops.left_index:\n",
    "    \n",
    "    loops_i = loops.query('left_index == @i')[['chrom', 'start2', 'end2', 'right_index']]\n",
    "    right_loop_BED = BedTool.from_dataframe(loops_i)\n",
    "\n",
    "    if len(right_loop_BED) > 1:\n",
    "        right_loop_keep = (right_loop_BED\n",
    "                           .sort()\n",
    "                           .merge(d = d, c = 4, o = 'collapse') # collapse indexes of the anchors merged\n",
    "                           .to_dataframe()\n",
    "                           .rename(columns = {'name':'right_index'}))\n",
    "        \n",
    "        if len(right_loop_keep) < len(loops_i):\n",
    "            \n",
    "            right_loop_keep['right_index'] = right_loop_keep['right_index'].str.split(',')\n",
    "            right_loop_keep = right_loop_keep.explode('right_index')\n",
    "\n",
    "            for ii in right_loop_keep.right_index.unique():\n",
    "\n",
    "                loops.loc[(loops.left_index == i) & \n",
    "                          (loops.right_index == int(ii)),\n",
    "                          'start2b'] = int(right_loop_keep.loc[right_loop_keep.right_index == ii,'start'])\n",
    "                loops.loc[(loops.left_index == i) & \n",
    "                          (loops.right_index == int(ii)),\n",
    "                          'end2b'] = int(right_loop_keep.loc[right_loop_keep.right_index == ii,'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6756f6a9-6bb2-476e-834f-dcaae310ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for the right anchor\n",
    "\n",
    "for i in right_loops.right_index:\n",
    "    \n",
    "    loops_i = loops.query('right_index == @i')[['chrom', 'start1', 'end1', 'left_index']]\n",
    "    left_loop_BED = BedTool.from_dataframe(loops_i)\n",
    "\n",
    "    if len(left_loop_BED) > 1:\n",
    "        left_loop_keep = (left_loop_BED\n",
    "                           .sort()\n",
    "                           .merge(d = 10000, c = 4, o = 'collapse')\n",
    "                           .to_dataframe()\n",
    "                           .rename(columns = {'name':'left_index'}))\n",
    "        \n",
    "        if len(left_loop_keep) < len(loops_i):\n",
    "            \n",
    "            left_loop_keep['left_index'] = left_loop_keep['left_index'].str.split(',')\n",
    "            left_loop_keep = left_loop_keep.explode('left_index')\n",
    "\n",
    "            for ii in left_loop_keep.left_index.unique():\n",
    "\n",
    "                loops.loc[(loops.right_index == i) & \n",
    "                          (loops.left_index == int(ii)),\n",
    "                          'start1b'] = int(left_loop_keep.loc[left_loop_keep.left_index == ii,'start'])\n",
    "                loops.loc[(loops.right_index == i) & \n",
    "                          (loops.left_index == int(ii)),\n",
    "                          'end1b'] = int(left_loop_keep.loc[left_loop_keep.left_index == ii,'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac64159e-3f93-410d-a1f3-e122242ee5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the coordinates of anchors that don't change\n",
    "\n",
    "loops.loc[np.isnan(loops.start1b), \"start1b\"] = loops.loc[np.isnan(loops.start1b), \"start1\"]\n",
    "loops.loc[np.isnan(loops.end1b), \"end1b\"] = loops.loc[np.isnan(loops.end1b), \"end1\"]\n",
    "\n",
    "loops.loc[np.isnan(loops.start2b), \"start2b\"] = loops.loc[np.isnan(loops.start2b), \"start2\"]\n",
    "loops.loc[np.isnan(loops.end2b), \"end2b\"] = loops.loc[np.isnan(loops.end2b), \"end2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5ce06-f38c-44e0-bc1d-6ae908cd5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new combined anchors\n",
    "\n",
    "before = len(loops)\n",
    "loops = loops[['chrom', 'start1b', 'end1b', 'start2b', 'end2b']].drop_duplicates().rename(columns = {'start1b':'start1', 'end1b':'end1',\n",
    "                                                                                                      'start2b':'start2', 'end2b':'end2'})\n",
    "\n",
    "loops['Index'] = loops.index\n",
    "\n",
    "print((1 - len(loops)/before*100), \"% of loops were combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55d95517-c89b-4ebf-bae6-ce3ce6b9b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get window to look for variants so that the E-P loop and variant can fit in the ~1Mb predictive window\n",
    "\n",
    "dist_cutoff = 900000\n",
    "\n",
    "center_coord1 = [(x+y)/2 for x,y in zip(loops.start1, loops.end1)]\n",
    "center_coord2 = [(x+y)/2 for x,y in zip(loops.start2, loops.end2)]\n",
    "\n",
    "remaining_dist = [dist_cutoff - abs(x-y) for x,y in zip(center_coord1, center_coord2)]\n",
    "\n",
    "# left and right most positions for variant to be in\n",
    "loops['left_cutoff'] = [int(x - y) for x,y in zip(center_coord1, remaining_dist)]\n",
    "loops.loc[loops.left_cutoff < 1,'left_cutoff'] = 1\n",
    "loops['right_cutoff'] = [int(x + y) for x,y in zip(center_coord2, remaining_dist)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b854d2ab-68a2-4373-a8dd-0e80fc6b521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.00785530398046 % of loops have an anchor at a promoter\n"
     ]
    }
   ],
   "source": [
    "# Get loops that overlap a promoter\n",
    "E_or_P = pd.concat(\n",
    "            [loops[['chrom', 'start1', 'end1', 'Index']].rename(columns = {'start1':'start', 'end1':'end'}),\n",
    "            loops[['chrom', 'start2', 'end2', 'Index']].rename(columns = {'start2':'start', 'end2':'end'})],\n",
    "            axis = 0)\n",
    "\n",
    "E_or_P.start = E_or_P.start.astype('int')\n",
    "E_or_P.end = E_or_P.end.astype('int')\n",
    "\n",
    "E_or_P_BED = BedTool.from_dataframe(E_or_P)\n",
    "\n",
    "promoter_loops = (E_or_P_BED\n",
    "                  .intersect(promoter_annot_PC_BED, wa = True, wb = True)\n",
    "                  .to_dataframe()\n",
    "                  .rename(columns = {'name':'loop_index', 'thickEnd':'gene'})\n",
    "                  [['loop_index', 'gene']])\n",
    "\n",
    "before = len(loops)\n",
    "\n",
    "# Only keep promoter loops\n",
    "loops = loops[[x in promoter_loops.loop_index for x in loops.Index]]\n",
    "\n",
    "print(len(loops)/before*100, '% of loops have an anchor at a promoter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5b62a5d-df94-47a8-9fc0-2f9f7460fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.78465563837295 % of genes are not expressed\n"
     ]
    }
   ],
   "source": [
    "# Get expression data\n",
    "\n",
    "tpm_cutoff = 0.5\n",
    "\n",
    "before = len(eN_exp)\n",
    "\n",
    "# Get only expressed genes\n",
    "eN_exp = eN_exp[eN_exp.TPM >= tpm_cutoff]\n",
    "\n",
    "print((before - len(eN_exp))/before*100, '% of genes are not expressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "489ecc9b-1b5b-4b65-bff1-fb03054dc0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.111344939735986 % of loops are on promoters that are not expressed\n"
     ]
    }
   ],
   "source": [
    "#Filter only loops that overlap promoters of expressed genes\n",
    "before = len(loops)\n",
    "\n",
    "loops_to_keep = promoter_loops.loop_index[[x in eN_exp.gene.values for x in promoter_loops.gene]].unique()\n",
    "\n",
    "loops = loops[[x in loops_to_keep for x in loops.Index]]\n",
    "\n",
    "print((before - len(loops))/before*100, '% of loops are on promoters that are not expressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "255667c0-2c8f-48c5-b59d-776d93b9a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % of loops are not accessible\n"
     ]
    }
   ],
   "source": [
    "# Get E-Ps where at least one is accessible\n",
    "E_or_P = pd.concat(\n",
    "            [loops[['chrom', 'start1', 'end1', 'Index']].rename(columns = {'start1':'start', 'end1':'end'}),\n",
    "            loops[['chrom', 'start2', 'end2', 'Index']].rename(columns = {'start2':'start', 'end2':'end'})],\n",
    "            axis = 0)\n",
    "\n",
    "E_or_P.start = E_or_P.start.astype('int')\n",
    "E_or_P.end = E_or_P.end.astype('int')\n",
    "\n",
    "E_or_P_BED = BedTool.from_dataframe(E_or_P)\n",
    "\n",
    "accessible_loops = (E_or_P_BED\n",
    "                  .intersect(ATAC_BED, wa = True, wb = True)\n",
    "                  .to_dataframe()\n",
    "                  .rename(columns = {'name':'loop_index'})\n",
    "                  [['loop_index']])\n",
    "\n",
    "before = len(loops)\n",
    "\n",
    "# Only keep accessible loops\n",
    "loops = loops[[x in accessible_loops.loop_index for x in loops.Index]]\n",
    "\n",
    "print((before - len(loops))/before*100, '% of loops are not accessible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f4380-2555-4fc1-a373-ef1a139f9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find loops near variants\n",
    "loops_windows_BED = BedTool.from_dataframe(loops[['chrom', 'left_cutoff', 'right_cutoff', 'Index']])\n",
    "\n",
    "loop_var_pairs = (loops_windows_BED\n",
    "                  .intersect(dnSVs_BED, wa = True, wb = True)\n",
    "                  .to_dataframe()\n",
    "                  .rename(columns = {'name':'loop_index', 'thickEnd':'var_index'})\n",
    "                  [['loop_index', 'var_index']])\n",
    "\n",
    "loop_var_pairs = loop_var_pairs.drop_duplicates() # If there are duplicates, they would be removed in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af344648-84b1-4a4d-8e54-46b307e08e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get E/Ps that each variant overlaps\n",
    "E_or_P = pd.concat(\n",
    "            [loops[['chrom', 'start1', 'end1', 'Index']].rename(columns = {'start1':'start', 'end1':'end'}),\n",
    "            loops[['chrom', 'start2', 'end2', 'Index']].rename(columns = {'start2':'start', 'end2':'end'})],\n",
    "            axis = 0)\n",
    "\n",
    "E_or_P_BED = BedTool.from_dataframe(E_or_P)\n",
    "\n",
    "var_on_E_or_P = (E_or_P_BED\n",
    "                  .intersect(SSC_SV_results_BED, wa = True, wb = True)\n",
    "                  .to_dataframe()\n",
    "                  .rename(columns = {'name':'loop_index', 'thickEnd':'var_index'})\n",
    "                  [['loop_index', 'var_index']])\n",
    "\n",
    "before = len(loop_var_pairs)\n",
    "\n",
    "# Filter out variants that overlap with E or P of loop they're in a trio with\n",
    "loop_var_pairs = pd.concat([loop_var_pairs, var_on_E_or_P, var_on_E_or_P]).drop_duplicates(keep=False)\n",
    "\n",
    "print(len(loop_var_pairs)/before*100, '% of E-P-variant trios: variant doesnt overlap E/P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271387f5-66ec-4242-b75f-0b3465595461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all loop and var info in one\n",
    "loop_var_coord = loop_var_pairs.copy()\n",
    "\n",
    "# Add info on loops to loop-variant pairs\n",
    "loop_var_coord = (loops\n",
    "                  .rename(columns = {'Index':'loop_index'})\n",
    "                  .drop(['left_cutoff', 'right_cutoff'], axis = 1)\n",
    "                  .merge(loop_var_coord, how = 'right')\n",
    "                 )\n",
    "\n",
    "# Add info on variants to loop-variant pairs\n",
    "loop_var_coord = (SSC_SV_results\n",
    "                  .drop('SSI', axis = 1)\n",
    "                  .rename(columns = {'index':'var_index', 'SSI_matrix':'SSI'})\n",
    "                  [['chrom', 'pos', 'End', 'svlen', 'svtype', 'role', 'var_index', 'MSE', 'correlation', 'SSI']]\n",
    "                  .merge(loop_var_coord, how = 'right')\n",
    "                 )\n",
    "\n",
    "loop_var_coord.insert(6, 'center_coord_var', [round((x+y)/2) for x,y in zip(loop_var_coord.End, loop_var_coord.pos)])\n",
    "\n",
    "# Get leftmost and rightmost coordinates of E, P and variant\n",
    "loop_var_coord['start'] = [min(x,y) for x,y in zip(loop_var_coord.start1, \n",
    "                                                    loop_var_coord.pos)]\n",
    "\n",
    "loop_var_coord['end'] = [max(x,y) for x,y in zip(loop_var_coord.end2, \n",
    "                                                    loop_var_coord.End)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c835a9-fcc1-486d-8808-f7e0f33db211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For duplications, center the duplicated sequence not the reference sequence\n",
    "# Extend the variant coordinates on the opposite side of the loop\n",
    "\n",
    "# Annotate variants based on whether they are on the left or right of the loop\n",
    "loop_var_coord.loc[loop_var_coord.pos < loop_var_coord.start1,'var_position'] = 'left'\n",
    "loop_var_coord.loc[loop_var_coord.pos > loop_var_coord.end2,'var_position'] = 'right'\n",
    "\n",
    "# Var to the left of the loop\n",
    "loop_var_coord.loc[(loop_var_coord.svtype == 'DUP') & \n",
    "                   (loop_var_coord.var_position == 'left'),\n",
    "                   'start'] -= loop_var_coord.loc[(loop_var_coord.svtype == 'DUP') & \n",
    "                                                  (loop_var_coord.var_position == 'left'),\n",
    "                                                   'svlen']\n",
    "\n",
    "# Var to the right of the loop\n",
    "loop_var_coord.loc[(loop_var_coord.svtype == 'DUP') & \n",
    "                   (loop_var_coord.var_position == 'right'),\n",
    "                   'end'] += loop_var_coord.loc[(loop_var_coord.svtype == 'DUP') & \n",
    "                                                (loop_var_coord.var_position == 'right'),\n",
    "                                                 'svlen']\n",
    "\n",
    "# Remove trios that exceed prediction window\n",
    "loop_var_coord = loop_var_coord[loop_var_coord.end - loop_var_coord.start < MB - (pixel_size*64)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a3fc9-13a4-469a-b500-781d29704692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For duplications, the alternate allele should be able to fit with the loop in the predictive window\n",
    "loop_var_coord.loc[(loop_var_coord.svtype == 'DUP') & \n",
    "                   (loop_var_coord.end - loop_var_coord.start + loop_var_coord.svlen > MB-(pixel_size*64)),\n",
    "                   'remove'] = 'yes'\n",
    "loop_var_coord = loop_var_coord[loop_var_coord.remove != 'yes'].drop('remove', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c46ae-a48b-4e48-b1b4-ecffc9952723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of variants in predictive window with loop\n",
    "len(loop_var_pairs.var_index.unique())/len(SSC_SV_results)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289c06d-eb4f-4eec-9979-0cae3c292623",
   "metadata": {},
   "source": [
    "### Get variant-specific shift values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b2182-5472-40c2-8c19-cdc673cfc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add shift value\n",
    "\n",
    "# when variant is left of the loop\n",
    "loop_var_coord.loc[(loop_var_coord.var_position == 'left'),\n",
    "                   'shift_by'] = [round((loop_end-var_end)/2) for loop_end,var_end in \n",
    "                               zip(loop_var_coord[(loop_var_coord.var_position == 'left')].end2, \n",
    "                                   loop_var_coord[(loop_var_coord.var_position == 'left')].End)]\n",
    "\n",
    "# For duplications, consider the variant as the duplicated sequence so it's not out of the window after shifting\n",
    "loop_var_coord.loc[(loop_var_coord.var_position == 'left') & (loop_var_coord.svtype == 'DUP'),\n",
    "                   'shift_by'] = [round((loop_end-var_end)/2+svlen/2) for loop_end,var_end,svlen in \n",
    "                               zip(loop_var_coord[(loop_var_coord.var_position == 'left') & (loop_var_coord.svtype == 'DUP')].end2, \n",
    "                                   loop_var_coord[(loop_var_coord.var_position == 'left') & (loop_var_coord.svtype == 'DUP')].End,\n",
    "                                   loop_var_coord[(loop_var_coord.var_position == 'left') & (loop_var_coord.svtype == 'DUP')].svlen)]\n",
    "\n",
    "\n",
    "# when variant is right of the loop\n",
    "loop_var_coord.loc[(loop_var_coord.var_position == 'right'),\n",
    "                   'shift_by'] = [-round((var_start-loop_start)/2) for var_start,loop_start in \n",
    "                               zip(loop_var_coord[(loop_var_coord.var_position == 'right')].pos, \n",
    "                                   loop_var_coord[(loop_var_coord.var_position == 'right')].start1)]\n",
    "\n",
    "# For duplications, consider the variant as the duplicated sequence so it's not out of the window after shifting\n",
    "loop_var_coord.loc[(loop_var_coord.var_position == 'right') & (loop_var_coord.svtype == 'DUP'),\n",
    "                   'shift_by'] = [-round((var_start-loop_start)/2+svlen/2) for var_start,loop_start,svlen in \n",
    "                               zip(loop_var_coord[(loop_var_coord.var_position == 'right') & (loop_var_coord.svtype == 'DUP')].pos, \n",
    "                                   loop_var_coord[(loop_var_coord.var_position == 'right') & (loop_var_coord.svtype == 'DUP')].start1,\n",
    "                                   loop_var_coord[(loop_var_coord.var_position == 'right') & (loop_var_coord.svtype == 'DUP')].svlen)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b678b8-73ce-4981-9b59-90ae43f2d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input files for SuPreMo\n",
    "\n",
    "for_supremo = loop_var_coord[~np.isnan(loop_var_coord.shift_by)][['chrom', 'pos', 'End', 'svtype', 'svlen', 'shift_by']]\n",
    "for_supremo.insert(2, 'REF', '-')\n",
    "for_supremo.insert(3, 'ALT', '-')\n",
    "for_supremo.columns = ['CHROM', 'POS', 'REF', 'ALT', 'END', 'SVTYPE', 'SVLEN', 'shift_by']\n",
    "\n",
    "# input file\n",
    "for_supremo.drop('shift_by', axis = 1).to_csv(f'{repo_dir}data/EP_for_SuPreMo.txt', \n",
    "                                           sep = '\\t', index = False)\n",
    "\n",
    "# shift file\n",
    "for_supremo[['shift_by']].to_csv(f'{repo_dir}data/EP_for_SuPreMo_shifts.txt', \n",
    "                                 sep = '\\t', index = False)\n",
    "\n",
    "# Weights file\n",
    "weights_file = pd.concat([loop_var_coord[['chrom', 'start1', 'end1']]\n",
    "                          .rename(columns = {'chrom':'chr', 'start1':'start', 'end1':'end'}),\n",
    "                          loop_var_coord[['chrom', 'start2', 'end2']]\n",
    "                          .rename(columns = {'chrom':'chr', 'start2':'start', 'end2':'end'})],\n",
    "                         axis = 0).reset_index(drop = True)\n",
    "weights_file.to_csv(f'{repo_dir}data/EP_for_SuPreMo_weights.txt', \n",
    "                    sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "528b9ce6-d066-4063-aa65-8c09383d37d3",
   "metadata": {},
   "source": [
    "# Run SuPreMo\n",
    "\n",
    "/pollard/data/projects/kgjoni/SuPreMo/scripts/SuPreMo.py \\\n",
    "/pollard/data/projects/kgjoni/Akita/ASD_project/SuPreMo_scoring/EP_for_SuPreMo.txt \\\n",
    "--get_Akita_scores \\\n",
    "--get_maps \\\n",
    "--get_tracks \\\n",
    "--shifts_file /pollard/data/projects/kgjoni/Akita/ASD_project/SuPreMo_scoring/EP_for_SuPreMo_shifts.txt \\\n",
    "--roi /pollard/data/projects/kgjoni/Akita/ASD_project/SuPreMo_scoring/EP_for_SuPreMo_weights.txt \\\n",
    "--roi_scales 10 1000000 \\\n",
    "--fa /pollard/data/projects/kgjoni/Akita_variant_scoring/data/hg38.fa \\\n",
    "--dir /pollard/data/projects/kgjoni/Akita/ASD_project/SuPreMo_scoring/EP_output3/ \\\n",
    "--file EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c187a6e-f0ae-43ca-ba6e-db34e7818098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output\n",
    "\n",
    "input_file = pd.read_csv(f'{repo_dir}data/EP_for_SuPreMo_full.txt', sep = '\\t')\n",
    "\n",
    "supremo_scores = pd.concat([input_file.reset_index(drop = True),\n",
    "                            pd.read_csv(f'{repo_dir}data/supremo-akita_output_weighted/', \n",
    "                                        sep = '\\t').drop('var_index', axis = 1)],\n",
    "                           axis = 1)\n",
    "for corr_score in ['correlation', 'corr_HFF_shifted']:\n",
    "    supremo_scores.loc[:,corr_score] = [1-x for x in supremo_scores[corr_score]]\n",
    "\n",
    "supremo_scores.to_csv(f'{repo_dir}data/EP_scores_eN_masked_SuPreMo_240913', \n",
    "                      sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb2372-f47a-46e1-924f-93be306ed8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c66fba-e172-4889-b354-493275ea69d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a832f-1661-4824-8750-bd6bb105e03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98993792-3793-4392-85c4-fb713b9d97cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
